# Bio5488 SP2025: Assignment 10

### Proteogenomics

**Due Date:** Friday, 4/4, 11:59 PM  
**Last Modified:** 3/24/2025

---
## Overview

The goal of this homework is to gain experience preparing a custom proteome reference database from genomic data, executing a mass spectrometry-based proteomics analysis pipeline, and critically evaluating the results. We will look for evidence of novel splicing events by searching for junction peptides that straddle two exons in publicly available CPTAC data.

Always remember to use an interactive job to run command-line tools (e.g., python, bowtie2, bcftools)
on the RIS. Once you submit an interactive job, you must activate your conda environment to use the
tools and dependencies within the docker image. 

```bash
$ bsub -Is -q workshop-interactive -G compute-workshop -a 'docker(takinwe1/bio5488:0.0)'
/bin/bash
$ conda activate bio5488
```
---
### Part 1: Download the Crux software suite.

•	Go to http://crux.ms/ and click Downloads
•	Select the download that matches your operating system
•	Agree to licensing terms and download release 4.1 of Crux
•	Unzip the download
•	The program we’ll be running from the command line is in the bin/ folder
o	Mac users- you may run into permissions issues the first time you run this. If you do, close the pop-up that says you can’t run it (but don’t let it delete the crux file). Go to Security and Privacy -> General. Somewhere near the lock on the bottom left there should be a message saying something to the effect of “crux was stopped from running, click here to change that”. Click the lock, enter your password/touch id, and allow crux to run. 

---
### Part 2: Obtain the SwissProt reference proteome from UniProtKB

•	Go to https://www.uniprot.org/ and click Species Proteomes
•	Type “Homo sapiens” in the search bar and search
•	Select the UP000005640 proteome
•	Click View proteins (underneath Components)
•	Select the “Reviewed (SwissProt)” Status on the top left
•	Click download
•	Select FASTA (canonical & isoforms) and uncompressed. Download.

---
### Part 3: Create a peptide database index for the human SwissProt proteome

•	Open up a terminal, create a directory for the assignment, and create a peptide index

```bash
	%  mkdir Assignment10
```

```bash
	%  cd Assignment10
```

```bash
	%  [PATH_TO_CRUX_BIN]/crux tide-index --overwrite T --missed-cleavages 2 --mods-spec K+229.162932 --nterm-peptide-mods-spec X+229.16293 [PATH_TO_PROTEOME] human_swissprot_TMT11
```
	--mods-spec K+229.162932 is a static TMT11 modification on lysines
•	Use unimod.org (login as guest) to lookup masses of other PTMs if you’re curious
	--nterm-peptide-mods-spec X+229.16293 is a static TMT11 mod on any residue on a peptide N-terminus.
	--missed-cleavages 2 includes peptides with up to 2 missed cleavages by trypsin, e.g. PEPTIDERKPEPTIDEK 
	The digestion enzyme is set to Trypsin by default
	The default min and max peptide lengths are 6 and 50, respectively.
	--overwrite T avoids the program stopping if output already exists (happens if you made a mistake and want to rerun something).
	This creates 2 folders – 
•	a peptide index called human_swissprot_TMT11. This isn’t human-readable.
•	A ‘crux-output’ folder with tide-index.log.txt and tide-index.params.txt text files. The log file is useful for answering the questions below but gets overwritten by every command. So, we suggest changing its name

•	Note how many unique peptides were generated from the log file.
o	Here, # of peptides = # of targets 
•	Let’s explore how the database size changes with variable modifications
o	Repeat the indexing but add up to 3 oxidized methionines per peptide:
```bash
	%  [PATH_TO_CRUX_BIN]/crux tide-index -–overwrite T -missed-cleavages 2 --mods-spec K+229.162932 --mods-spec 3M+15.994915 --nterm-peptide-mods-spec X+229.16293 [PATH_TO_PROTEOME]/UP000005640_9606.fasta human_swissprot_TMT11_oxM
```
o	Note the number of peptides generated (“INFO: Created XXX peptides.”)
	After reporting the number of targets, it will report the number of peptides, we want the number of peptides.
o	Now also add up to 3 phosphorylations per peptide:
```bash
	%  [PATH_TO_CRUX_BIN]/crux tide-index -–overwrite T -missed-cleavages 2 --mods-spec K+229.162932 --mods-spec 3M+15.994915 --mods-spec 3STY+79.966331 --nterm-peptide-mods-spec X+229.16293 [PATH_TO_PROTEOME]/UP000005640_9606.fasta human_swissprot_TMT11_oxM_pSTY
```

**Question 1:**
 How many unique peptides were generated for our database using no variable PTMs, up to 3 oxidized methionines, and 3 oxidized methionines + 3 phosphorylations of STYs?

**Question 2:**
 What identification results could you find if you forgot to add the TMT modifications to the database?


 ---
 ### Part 4: Download raw mass spectrometry data from CPTAC’s lung adenocarcinoma study.
 •	Go to https://proteomic.datacommons.cancer.gov/pdc/ 
 •	Click Lung Adenocarcinoma
 •	We’ll only look at global proteome data, not phosphorylation enriched data, so find the row that says APOLLO-LUAD Proteome. Click on the 360 under the mzML header (mzML is the open standard data format).
 o	You can use the .raw files as well, but Crux only provides support to read .raw files on windows.
 •	Download the AP1_QEHF2_AP1_9_18.mzML.gz file
 o	In the interest of time, we’ll only download 1 file, but in reality each sample is divided into multiple fractions (usually 25) and often analyzed in two technical replicates.
 •	Unzip the file and stick into your assignment folder
 

---
### Part 5: Perform a database search (peptide identification pipeline only)
•	Use the terminal to run the following command:
```bash
	% [PATH_TO_CRUX_BIN]/crux pipeline --overwrite T AP1_QEHF2_AP1_9_18.mzML human_swissprot_TMT11/
```
o	This will run a database search (Tide/Sequest), a peptide inference method (Percolator), and false discovery rate estimation.
•	The peptide identifications will be in crux-output/percolator.target.peptides.txt
o	You will be turning this text file in.

---
### Part 6: Create a 6-frame translation of the human genome and perform a database search
•	Easy option: download the 6-frame translated FASTA file from box: https://wustl.box.com/s/aduuzpxud4xzvabncz51o9tmx6btf6be
•	Do it yourself option (very slow, only if you need to do it for a project one day): download transcript data from RefSeq’s Consensus CDS project: https://ftp.ncbi.nlm.nih.gov/pub/CCDS/current_human/ 
o	Grab the CCDS_nucleotide.20221027.fna.gz file
o	Use a Docker image for the emboss suite
```bash
	% docker pull biocontainers/emboss:v6.6.0dfsg-7b1-deb_cv
```
```bash
	% docker run --rm -it -v [PATH_TO_FOLDER_WITH_FASTA]/ data biocontainers/emboss:v6.6.0dfsg-7b1-deb_cv1 /bin/bash
```
	Write a little script to call the following command on each entry in your fasta file and concatenate the result: % sixpack -sequence my_sequence.fna
	There are other tools out there, but most have GUIs.
•	Create a peptide index of your 6-frame translated database
```bash
	%  [PATH_TO_CRUX_BIN]/crux tide-index --overwrite T --missed-cleavages 2 --mods-spec K+229.162932 --nterm-peptide-mods-spec X+229.16293 [PATH_TO_PROTEOME] human_CCDS_6frame_TMT11
```
•	Database search
o	This will overwrite your previous results, so either create a new directory or move the previous results somewhere.
```bash
	% [PATH_TO_CRUX_BIN]/crux pipeline --overwrite T AP1_QEHF2_AP1_9_18.mzML human_ CCDS_6frame_MT11/
```
	You will be turning the percolator.target.peptides.txt file in

**Question 3:**
 How much larger is the 6-frame proteome in terms of peptides generated by tide-index?

**Question 4:** How many peptides were ID’ed at a 5% FDR using both methods? Why did we ID fewer peptides with a bigger database?

**Question 5:**
 List the out-of-frame peptides identified at a 1% FDR (percolator q-value). You can tell they’re not in the expected frame if the none of the IDs in the in “protein id” column end in “true:0”. “true” refers to it being the strand given in the nucleotide fasta file, and 0 referring to the translation start index (out of frame sequences would start somewhere else). BLAST them (https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastp&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome) against the human proteome SwissProt and determine if there is an alternative in-frame explanation for each peptide.
So, for each peptide you list mention whether or not there is an alternative in-frame explanation, and if so what it is. 


### What to turn in:

•	README.txt file with answers to each of the questions and the commands as they were in your terminal or command line to generate the answers
•	4 tide-index.log.txt files from your indexing
o	human_swissprot_tide-index.log.txt
o	human_swissprot_oxM_tide-index.log.txt
o	human_swissprot_oxM_pSTY_tide-index.log.txt 
o	human_CCDS_6frame _tide-index.log.txt
•	2 percolator.target.peptides.txt files from each of your database searches 
o	human_swissprot_percolator.target.peptides.txt file 
o	human_CCDS_6frame _percolator.target.peptides.txt file
•	2 pipeline.log.txt files from each of your database searches
o	human_swissprot_pipeline.log.txt file 
o	human_CCDS_6frame_ pipeline.log.txt file
